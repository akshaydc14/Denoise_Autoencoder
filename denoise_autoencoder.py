# -*- coding: utf-8 -*-
"""Denoise Autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HMBeBIKiKHX5uCngkCuNddNG4F-53OPJ
"""

import numpy as np
from keras.datasets import mnist

(x_train,_),(x_test,_)=mnist.load_data()
x_train.shape

from matplotlib import pyplot as plt
fig,axes = plt.subplots(2,10,figsize=(16,4))

count=0

for i in range(2):
  for j in range(10):
    axes[i,j].imshow(x_train[count],cmap='gray')
    count+=1

x_train=x_train/255.0
x_test=x_test/255.0

##Preparing noise image dataset

noise_factor = 0.1
x_train_noise=x_train+noise_factor*np.random.normal(loc=0.,scale=1.,size=x_train.shape)
x_test_noise=x_test+noise_factor*np.random.normal(loc=0.,scale=1.,size=x_test.shape)

x_train.shape

##visualize noisy data

fig,axes = plt.subplots(2,10,figsize=(16,4))

count=0

for i in range(2):
  for j in range(10):
    axes[i,j].imshow(x_train_noise[count],cmap='gray')
    count+=1

x_train = x_train.reshape(x_train.shape[0],28,28,1)
x_test = x_test.reshape(x_test.shape[0],28,28,1)
x_train_noise = x_train_noise.reshape(x_train_noise.shape[0],28,28,1)
x_test_noise = x_test_noise.reshape(x_test.shape[0],28,28,1)

x_train.shape, x_train_noise.shape

from keras.models import Model
from keras.layers import Input, Conv2D , MaxPool2D , Dense ,UpSampling2D,BatchNormalization
from keras.callbacks import ModelCheckpoint

import tensorflow as tf

devices = tf.config.experimental.list_physical_devices("GPU")
tf.config.experimental.set_memory_growth(devices[0],enable =True)

#encoder
encoder_input = Input(shape=x_train.shape[1:])
x = Conv2D(32,(3,3),activation ='relu',padding='same')(encoder_input)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=(2,2),padding ='same')(x)
x= Conv2D(32,(3,3),activation ='relu',padding='same')(x)
x = BatchNormalization()(x)
encoded= MaxPool2D(pool_size=(2,2),padding='same')(x)

#decoder
x = Conv2D(32,(3,3),activation ='relu',padding ='same')(encoded)
x = BatchNormalization()(x)
x= UpSampling2D()(x)
x = Conv2D(32,(3,3),activation='relu',padding='same')(x)
x = BatchNormalization()(x)
x = UpSampling2D()(x)
decoded = Conv2D(1,(3,3),activation='sigmoid',padding='same')(x)

autoencoder = Model(encoder_input,decoded,name='Denoising_Model')
autoencoder.summary()

autoencoder.compile(loss = 'binary_crossentropy',optimizer='adam')

checkpoint = ModelCheckpoint("denoising_model.h5", save_best_only=True, save_weights_only=False, verbose = 1)
history = autoencoder.fit(x_train_noise, x_train, batch_size = 128, epochs = 50, callbacks = checkpoint, validation_split = 0.25, verbose = 1)

# load best performance model
from keras.models import load_model
autoencoder = load_model('denoising_model.h5')
autoencoder.summary()

def visualize_data(data, row, column):
    data = data.reshape(data.shape[0], 28,28)
    count = 0
    fig, axes = plt.subplots(row, column, figsize = (16,4))
    for i in range(row):
        for j in range(column):
            axes[i,j].imshow(data[count], cmap = 'gray')
            count+=1

visualize_data(x_test_noise[:20], 2,10)

pred = autoencoder.predict(x_test_noise[:20])
pred.shape

visualize_data(pred, 2, 10)

